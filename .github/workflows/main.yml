name: Deploy Medusa Backend to AWS ECS Fargate

on:
  push:
    branches:
      - main # Trigger on pushes to the main branch

env:
  AWS_REGION: ap-south-1 # IMPORTANT: Change to your chosen AWS region (e.g., us-east-1, ap-south-1)
  PROJECT_NAME: ${{ vars.PROJECT_NAME }}
  ECR_REPOSITORY: medusa-backend # Must match the ECR repository name in terraform/modules/ecs-fargate/main.tf
  ECS_CLUSTER: ${{ vars.PROJECT_NAME }}-cluster
  ECS_SERVICE: ${{ vars.PROJECT_NAME }}-medusa-backend-service
  ECS_CONTAINER_NAME: medusa-backend # Must match the container name in ECS task definition
  DB_USERNAME: ${{ secrets.DB_USERNAME }}
  DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
  TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}
  STORE_CORS: ${{ vars.STORE_CORS }}
  ADMIN_CORS: ${{ vars.ADMIN_CORS }}
  AUTH_CORS: ${{ vars.AUTH_CORS }}
  JWT_SECRET: ${{ secrets.JWT_SECRET }}
  COOKIE_SECRET: ${{ secrets.COOKIE_SECRET }}
  NODE_ENV: production # Set the Node.js environment to production

permissions:
  contents: read
  packages: write # Needed for pushing Docker images to GitHub Packages (if used)
  id-token: write # Needed for OIDC if you switch from Access Keys

jobs:
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    environment: production # Using a GitHub environment for better security and organization

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.12.2" # Specify a compatible version, e.g., "1.8.x" or ">=1.0.0"

      - name: Terraform Init
        run: terraform init -backend-config="bucket=${{ env.TF_STATE_BUCKET }}" -backend-config="key=${{ env.PROJECT_NAME }}/terraform.tfstate" -backend-config="region=${{ env.AWS_REGION }}" -backend-config="dynamodb_table=terraform-lock-table"
        working-directory: ./terraform

      - name: Terraform Plan
        run: terraform plan -var="aws_region=${{ env.AWS_REGION }}" -var="db_username=${{ env.DB_USERNAME }}" -var="db_password=${{ env.DB_PASSWORD }}" -var="store_cors=${{ env.STORE_CORS }}" -var="admin_cors=${{ env.ADMIN_CORS }}" -var="auth_cors=${{ env.AUTH_CORS }}"
        working-directory: ./terraform

      - name: Terraform Apply
        id: terraform-apply-step # Added ID to this step to reference its outputs (though not directly used for task-def input)
        run: terraform apply -auto-approve -var="aws_region=${{ env.AWS_REGION }}" -var="db_username=${{ env.DB_USERNAME }}" -var="db_password=${{ env.DB_PASSWORD }}" -var="store_cors=${{ env.STORE_CORS }}" -var="admin_cors=${{ env.ADMIN_CORS }}" -var="auth_cors=${{ env.AUTH_CORS }}"
        working-directory: ./terraform

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Get ECR Repository URI
        id: get-ecr-uri
        run: echo "ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}" >> $GITHUB_ENV

      - name: Build and push Docker image
        id: build-and-push-image # Added ID to this step
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }} -f medusa-backend/Dockerfile .
          docker push $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}
          # Output the full image URI for later steps
          echo "IMAGE_URI=$ECR_REGISTRY/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}" >> $GITHUB_OUTPUT

           # --- CORRECTED MIGRATION STEP (using AWS CLI) ---
      - name: Run Medusa DB Migrations (AWS CLI)
        id: run-migrations-task
        run: |
          # Define the database URL
          DB_URL="postgresql://${{ env.DB_USERNAME }}:${{ env.DB_PASSWORD }}@${{ env.DB_ENDPOINT }}:5432/${{ env.DB_NAME }}"

          # Get the latest active task definition ARN.
          TASK_DEFINITION_ARN=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }} \
                                --query 'services[0].taskDefinition' --output text)
          
          # Fallback if service task definition is not found (e.g., first deployment)
          if [ -z "$TASK_DEFINITION_ARN" ] || [ "$TASK_DEFINITION_ARN" == "None" ]; then
              echo "Service task definition not found or service not yet created. Using task definition family directly."
              # This assumes your Terraform has been applied at least once to create the task definition.
              TASK_DEFINITION_ARN="${{ env.PROJECT_NAME }}-medusa-backend-task"
          fi

          echo "Using Task Definition ARN/Family: $TASK_DEFINITION_ARN"

          # Construct the command override
          # Note: No 'image' override here, as the task definition already has the correct image
          COMMAND_OVERRIDE="[\"/bin/sh\", \"-c\", \"DATABASE_URL=${DB_URL} yarn run medusa db:setup\"]"

          # Get the task execution role ARN from the task definition
          # This is necessary for Fargate tasks if not explicitly set in the run-task command
          EXECUTION_ROLE_ARN=$(aws ecs describe-task-definition --task-definition $TASK_DEFINITION_ARN \
                               --query 'taskDefinition.executionRoleArn' --output text)

          echo "Using Execution Role ARN: $EXECUTION_ROLE_ARN"

          # Run the one-off ECS task for migrations
          RUN_TASK_OUTPUT=$(aws ecs run-task --cluster ${{ env.ECS_CLUSTER }} \
                                              --task-definition $TASK_DEFINITION_ARN \
                                              --launch-type FARGATE \
                                              --network-configuration "awsvpcConfiguration={subnets=[${{ secrets.PRIVATE_SUBNETS }}],securityGroups=[${{ secrets.APP_SECURITY_GROUP }}],assignPublicIp=DISABLED}" \
                                              --overrides "containerOverrides=[{name='${{ env.ECS_CONTAINER_NAME }}',command=${COMMAND_OVERRIDE}}]" \
                                              --count 1 \
                                              --started-by "github-actions-migrations" \
                                              --platform-version LATEST \
                                              --query 'tasks[0].taskArn' --output text --no-cli-pager)
          
          if [ -z "$RUN_TASK_OUTPUT" ]; then
              echo "Error: Failed to start migration task. Check AWS CLI output and permissions."
              exit 1
          fi

          TASK_ARN=$RUN_TASK_OUTPUT
          echo "Migration Task ARN: $TASK_ARN"

          # Wait for the task to complete
          echo "Waiting for migration task to complete..."
          aws ecs wait tasks-stopped --cluster ${{ env.ECS_CLUSTER }} --tasks $TASK_ARN --no-cli-pager

          TASK_STATUS=$(aws ecs describe-tasks --cluster ${{ env.ECS_CLUSTER }} --tasks $TASK_ARN \
                                               --query 'tasks[0].lastStatus' --output text --no-cli-pager)
          EXIT_CODE=$(aws ecs describe-tasks --cluster ${{ env.ECS_CLUSTER }} --tasks $TASK_ARN \
                                             --query 'tasks[0].containers[0].exitCode' --output text --no-cli-pager)
          STOP_REASON=$(aws ecs describe-tasks --cluster ${{ env.ECS_CLUSTER }} --tasks $TASK_ARN \
                                               --query 'tasks[0].stoppedReason' --output text --no-cli-pager)

          echo "Migration Task Status: $TASK_STATUS"
          echo "Migration Task Exit Code: $EXIT_CODE"
          echo "Migration Task Stop Reason: $STOP_REASON"

          if [ "$EXIT_CODE" -ne 0 ]; then
              echo "Error: Migration task failed with exit code $EXIT_CODE. Reason: $STOP_REASON"
              echo "Check CloudWatch logs for task ARN: $TASK_ARN"
              exit 1
          else
              echo "Migration task completed successfully."
          fi
      # --- END CORRECTED MIGRATION STEP ---


      # NEW STEP: Fetch the latest Task Definition JSON from AWS
      - name: Fetch current ECS Task Definition
        id: fetch-task-definition
        run: |
          # Get the latest active task definition ARN for the service
          TASK_DEF_ARN=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }} --query 'services[0].taskDefinition' --output text)
          echo "Fetched Task Definition ARN: $TASK_DEF_ARN"

          # Describe the task definition and output its JSON to a file
          aws ecs describe-task-definition --task-definition $TASK_DEF_ARN --query 'taskDefinition' > task-definition.json

          # Set the task definition file path as an output for this step
          echo "TASK_DEFINITION_FILE=task-definition.json" >> $GITHUB_OUTPUT

      # NEW STEP: Render the Task Definition with the new image
      - name: Render new ECS task definition with updated image
        id: render-task-def
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: ${{ steps.fetch-task-definition.outputs.TASK_DEFINITION_FILE }} # Use the fetched JSON file
          container-name: ${{ env.ECS_CONTAINER_NAME }} # Your Medusa container name
          image: ${{ steps.build-and-push-image.outputs.IMAGE_URI }} # Use the image URI from the build step

      - name: Deploy Amazon ECS task definition
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition: ${{ steps.render-task-def.outputs.task-definition }} # Use the output from the render step
          service: ${{ env.ECS_SERVICE }}
          cluster: ${{ env.ECS_CLUSTER }}
          wait-for-service-stability: true